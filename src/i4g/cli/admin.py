"""Administrative utilities for the i4g platform."""

from __future__ import annotations

import argparse
import json
import os
import subprocess
import sys
import warnings
from pathlib import Path

from rich.console import Console

from i4g.services.factories import build_review_store, build_vector_store
from i4g.settings import get_settings

# Fix for OpenMP runtime conflict on macOS.
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

console = Console()
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

SETTINGS = get_settings()


def ensure_ollama_running() -> bool:
    """
    Quick connectivity check for Ollama.
    Returns True if the Ollama daemon is reachable, False otherwise.
    """
    try:
        result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=3)
        return result.returncode == 0
    except Exception:
        return False


def run_query(args: argparse.Namespace) -> None:
    from i4g.rag.pipeline import build_scam_detection_chain

    if not ensure_ollama_running():
        console.print("[red]âŒ Ollama is not running. Start it first with:[/red]")
        console.print("    ollama serve\n")
        sys.exit(1)

    console.print("[green]âœ… Ollama detected. Loading vectorstore...[/green]")

    try:
        store = build_vector_store(backend=args.backend)
    except Exception as e:  # pragma: no cover - defensive logging
        console.print(f"[red]Failed to initialize vectorstore:[/red] {e}")
        console.print("Make sure you ran `python scripts/build_index.py` successfully.")
        sys.exit(1)

    console.print("[cyan]ðŸ”— Building scam detection chain...[/cyan]")
    chain = build_scam_detection_chain(store)

    console.print(f"[cyan]ðŸ¤– Analyzing question:[/cyan] {args.question}\n")

    try:
        result = chain.invoke({"question": args.question})
    except Exception as e:  # pragma: no cover - defensive logging
        console.print(f"[red]âŒ Query failed:[/red] {e}")
        sys.exit(1)

    console.print("\n[bold green]ðŸ§  Scam Detection Result:[/bold green]")
    console.print(result)

    console.print("\n[dim]Note: Results are generated by a local LLM using RAG context retrieval.[/dim]")


def export_saved_searches(args: argparse.Namespace) -> None:
    """Dump saved searches to JSON."""
    store = build_review_store()
    owner_filter = None if args.all else (args.owner or None)
    records = store.list_saved_searches(owner=owner_filter, limit=args.limit)
    include_tags = set(t.strip().lower() for t in (args.include_tags or []))
    if include_tags:
        records = [r for r in records if include_tags.intersection({t.lower() for t in (r.get("tags") or [])})]
    for record in records:
        record.pop("created_at", None)
        if record.get("tags") is None:
            record["tags"] = []
    if args.split and args.output:
        base = Path(args.output)
        base.mkdir(parents=True, exist_ok=True)
        by_owner: dict[str, list[dict[str, object]]] = {}
        for record in records:
            owner = record.get("owner") or "shared"
            by_owner.setdefault(owner, []).append(record)
        for owner, rows in by_owner.items():
            fname = base / f"saved_searches_{owner}.json"
            fname.write_text(json.dumps(rows, indent=2))
            console.print(f"[green]âœ… Exported {len(rows)} saved search(es) to {fname}")
    else:
        data = json.dumps(records, indent=2)
        if args.output:
            Path(args.output).write_text(data)
            console.print(f"[green]âœ… Exported {len(records)} saved search(es) to {args.output}")
        else:
            console.print(data)


def import_saved_searches(args: argparse.Namespace) -> None:
    """Load saved searches from JSON file/stdin."""
    from i4g.api.review import SavedSearchImportRequest

    store = build_review_store()
    content = Path(args.input).read_text() if args.input else sys.stdin.read()
    try:
        payload = json.loads(content)
    except json.JSONDecodeError as exc:
        console.print(f"[red]âŒ Invalid JSON:[/red] {exc}")
        sys.exit(1)

    include_tags = set(t.strip().lower() for t in (args.include_tags or []))
    items = payload if isinstance(payload, list) else [payload]
    imported = 0
    skipped = 0
    for item in items:
        try:
            req = SavedSearchImportRequest(**item)
            if include_tags and not include_tags.intersection({t.lower() for t in (req.tags or [])}):
                skipped += 1
                continue
            store.import_saved_search(req.model_dump(), owner=None if args.shared else args.owner)
            imported += 1
        except Exception as exc:  # pragma: no cover - defensive logging
            skipped += 1
            console.print(f"[yellow]Skipped #{imported + skipped}: {exc}[/yellow]")
    console.print(f"[green]âœ… Imported {imported} saved search(es); {skipped} skipped.")


def prune_saved_searches(args: argparse.Namespace) -> None:
    store = build_review_store()
    records = store.list_saved_searches(owner=args.owner, limit=1000)
    tags_filter = set(t.strip().lower() for t in (args.tags or []))
    to_delete = []
    for record in records:
        tags = {t.lower() for t in (record.get("tags") or [])}
        if tags_filter and not tags_filter.intersection(tags):
            continue
        to_delete.append(record)

    if not to_delete:
        console.print("[yellow]No saved searches matched the criteria.")
        return

    for record in to_delete:
        owner = record.get("owner") or "shared"
        console.print(f"[cyan]- {record.get('name')} (owner={owner}, tags={record.get('tags')})")

    if args.dry_run:
        console.print(f"[green]Dry run: {len(to_delete)} saved search(es) would be deleted.")
        return

    deleted = 0
    for record in to_delete:
        if store.delete_saved_search(record["search_id"]):
            deleted += 1
    console.print(f"[green]âœ… Deleted {deleted} saved search(es).")


def bulk_update_saved_search_tags(args: argparse.Namespace) -> None:
    if not any([args.add, args.remove, args.replace is not None]):
        console.print("[red]Provide --add, --remove, or --replace to adjust tags.[/red]")
        sys.exit(1)

    if args.replace is not None and (args.add or args.remove):
        console.print("[yellow]âš ï¸ --replace overrides --add/--remove; add/remove values will be ignored.[/yellow]")

    store = build_review_store()
    normalized_add = [t.strip() for t in (args.add or []) if t.strip()]
    normalized_remove = [t.strip() for t in (args.remove or []) if t.strip()]
    normalized_replace = [t.strip() for t in (args.replace or []) if t.strip()] if args.replace is not None else None

    summary_records = []
    target_ids = []

    if args.search_id:
        target_ids = [sid for sid in args.search_id if sid.strip()]
        for sid in target_ids:
            record = store.get_saved_search(sid)
            if record:
                summary_records.append(record)
    else:
        records = store.list_saved_searches(owner=args.owner, limit=args.limit)
        tags_filter = {t.strip().lower() for t in (args.tags or []) if t.strip()}
        if tags_filter:
            records = [r for r in records if tags_filter.intersection({t.lower() for t in (r.get("tags") or [])})]
        summary_records = records
        target_ids = [r["search_id"] for r in records]

    target_ids = list(dict.fromkeys(target_ids))

    if not target_ids:
        console.print("[yellow]No saved searches matched the criteria.")
        return

    if args.search_id:
        found_ids = {record["search_id"] for record in summary_records}
        missing_ids = [sid for sid in target_ids if sid not in found_ids]
        if missing_ids:
            console.print(
                "[yellow]Warning:[/yellow] the following saved search ID(s) were not found and will be skipped: "
                + ", ".join(missing_ids)
            )

    if args.dry_run:
        console.print(f"[green]Dry run:[/green] would update {len(target_ids)} saved search(es).")
        for record in summary_records[:10]:
            owner = record.get("owner") or "shared"
            console.print(f"  - {record.get('name')} (owner={owner}, tags={record.get('tags') or []})")
        if len(summary_records) > 10:
            console.print(f"  ...and {len(summary_records) - 10} more.")
        return

    updated = store.bulk_update_tags(
        target_ids,
        add=normalized_add,
        remove=normalized_remove,
        replace=normalized_replace,
    )
    console.print(f"[green]âœ… Updated tags for {updated} saved search(es).")


def export_tag_presets(args: argparse.Namespace) -> None:
    store = build_review_store()
    presets = store.list_tag_presets(owner=args.owner, limit=1000)
    data = json.dumps(presets, indent=2)
    if args.output:
        Path(args.output).write_text(data)
        console.print(f"[green]âœ… Exported {len(presets)} tag preset(s) to {args.output}")
    else:
        console.print(data)


def import_tag_presets(args: argparse.Namespace) -> None:
    content = Path(args.input).read_text() if args.input else sys.stdin.read()
    try:
        payload = json.loads(content)
    except json.JSONDecodeError as exc:
        console.print(f"[red]âŒ Invalid JSON:[/red] {exc}")
        sys.exit(1)
    items = payload if isinstance(payload, list) else [payload]
    presets = []
    for item in items:
        tags = item.get("tags") or []
        if tags and tags not in presets:
            presets.append(tags)
    if not presets:
        console.print("[yellow]No tag presets found in input.")
        return
    output = json.dumps(presets, indent=2)
    if args.input:
        Path(args.input).write_text(output)
        console.print(f"[green]âœ… Normalized {len(presets)} tag preset(s).")
    else:
        console.print(output)


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="i4g administrative utilities.")
    sub = parser.add_subparsers(dest="command", required=True)

    query = sub.add_parser("query", help="Run scam detection query.")
    query.add_argument("--question", required=True, help="User question text.")
    query.add_argument(
        "--backend",
        type=str,
        default=SETTINGS.vector.backend,
        choices=["chroma", "faiss"],
        help="Vector backend to use (overrides I4G_VECTOR_BACKEND).",
    )
    query.set_defaults(func=run_query)

    export = sub.add_parser("export-saved-searches", help="Export saved searches to JSON.")
    export.add_argument("--limit", type=int, default=100, help="Max entries to export.")
    export.add_argument(
        "--all",
        action="store_true",
        help="Include shared searches along with personal ones.",
    )
    export.add_argument("--owner", help="Filter by owner username (ignored if --all).")
    export.add_argument("--output", help="Output file; omit for stdout.")
    export.add_argument(
        "--split",
        action="store_true",
        help="When writing to a folder, create one file per owner.",
    )
    export.add_argument(
        "--include-tags",
        nargs="*",
        help="Only export saved searches matching these tags (case-insensitive).",
    )
    export.set_defaults(func=export_saved_searches)

    imp = sub.add_parser("import-saved-searches", help="Import saved searches from JSON.")
    imp.add_argument("--input", help="JSON file path (defaults to stdin).")
    imp.add_argument(
        "--owner",
        default=None,
        help="Owner username for imported searches (default: current user).",
    )
    imp.add_argument("--shared", action="store_true", help="Import into shared scope (owner=NULL).")
    imp.add_argument(
        "--include-tags",
        nargs="*",
        help="Only import saved searches that include these tags.",
    )
    imp.set_defaults(func=import_saved_searches)

    prune = sub.add_parser("prune-saved-searches", help="Delete saved searches by owner/tag filters.")
    prune.add_argument(
        "--owner",
        help="Delete saved searches belonging to this owner (omit for shared).",
    )
    prune.add_argument(
        "--tags",
        nargs="*",
        help="Only delete saved searches containing any of these tags.",
    )
    prune.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview deletions without applying them.",
    )
    prune.set_defaults(func=prune_saved_searches)

    bulk = sub.add_parser(
        "bulk-update-tags",
        help="Add, remove, or replace saved-search tags in bulk.",
    )
    bulk.add_argument("--owner", help="Filter saved searches to this owner (default: all owners).")
    bulk.add_argument(
        "--tags",
        nargs="*",
        help="Only target saved searches containing these tags (any match).",
    )
    bulk.add_argument(
        "--search-id",
        nargs="*",
        help="Explicit saved search IDs to update (skips owner/tag filters).",
    )
    bulk.add_argument("--add", nargs="+", help="Tags to add to each matched saved search.")
    bulk.add_argument("--remove", nargs="+", help="Tags to remove from each matched saved search.")
    bulk.add_argument(
        "--replace",
        nargs="+",
        help="Replace the existing tag set with this list (overrides --add/--remove).",
    )
    bulk.add_argument(
        "--limit",
        type=int,
        default=200,
        help="Max saved searches to inspect when filtering.",
    )
    bulk.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview the changes without persisting them.",
    )
    bulk.set_defaults(func=bulk_update_saved_search_tags)

    export_tags = sub.add_parser("export-tag-presets", help="Export tag presets derived from saved searches.")
    export_tags.add_argument("--owner", help="Filter presets to this owner (omit for shared).")
    export_tags.add_argument("--output", help="File to write JSON (stdout if omitted).")
    export_tags.set_defaults(func=export_tag_presets)

    import_tags = sub.add_parser("import-tag-presets", help="Import tag presets and append as filter presets.")
    import_tags.add_argument("--input", help="JSON file path (defaults to stdin).")
    import_tags.set_defaults(func=import_tag_presets)

    return parser


def main(argv: list[str] | None = None) -> None:
    parser = build_parser()
    args = parser.parse_args(args=argv)
    args.func(args)


__all__ = [
    "build_parser",
    "main",
    "run_query",
]
