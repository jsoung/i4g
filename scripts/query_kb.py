"""
Command-line scam detection query interface using LangChain (v0.2+) and Ollama.

This CLI:
1. Loads the local vectorstore.
2. Builds a scam detection RAG chain using Ollama.
3. Answers user questions about possible scams in natural language.
"""

import argparse
import os
import sys
import subprocess
import warnings
from rich.console import Console

# Fix for OpenMP runtime conflict on macOS.
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

from i4g.store.vector import VectorStore
from i4g.rag.pipeline import build_scam_detection_chain

console = Console()
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)


def ensure_ollama_running() -> bool:
    """
    Quick connectivity check for Ollama.
    Returns True if the Ollama daemon is reachable, False otherwise.
    """
    try:
        result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=3)
        return result.returncode == 0
    except Exception:
        return False


def main() -> None:
    """Main entrypoint for scam detection CLI."""
    parser = argparse.ArgumentParser(description="Query the local scam detection knowledge base.")
    parser.add_argument("--question", type=str, required=True, help="User question text.")
    args = parser.parse_args()

    # Step 1. Ensure Ollama is running
    if not ensure_ollama_running():
        console.print("[red]‚ùå Ollama is not running. Start it first with:[/red]")
        console.print("    ollama serve\n")
        sys.exit(1)

    console.print("[green]‚úÖ Ollama detected. Loading vectorstore...[/green]")

    # Step 2. Initialize VectorStore
    try:
        store = VectorStore()
    except Exception as e:
        console.print(f"[red]Failed to initialize vectorstore:[/red] {e}")
        console.print("Make sure you ran `python scripts/build_index.py` successfully.")
        sys.exit(1)

    # Step 3. Build the scam detection chain
    console.print("[cyan]üîó Building scam detection chain...[/cyan]")
    chain = build_scam_detection_chain(store)

    # Step 4. Query the chain
    console.print(f"[cyan]ü§ñ Analyzing question:[/cyan] {args.question}\n")

    try:
        result = chain.invoke({"question": args.question})
    except Exception as e:
        console.print(f"[red]‚ùå Query failed:[/red] {e}")
        sys.exit(1)

    console.print("\n[bold green]üß† Scam Detection Result:[/bold green]")
    console.print(result)

    console.print("\n[dim]Note: Results are generated by a local LLM using RAG context retrieval.[/dim]")


if __name__ == "__main__":
    main()
